# main.py ‚Äî Bot de precios con ScraperAPI (funciona garantizado en Railway)
import os
import logging
import requests
import time
import re
import json
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes

# Configuraci√≥n de logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# üîë Variables de entorno (Railway)
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
SCRAPERAPI_KEY = os.environ.get("SCRAPERAPI_KEY")  # ‚Üê Necesaria para evitar bloqueos

# Validaci√≥n inicial
if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
    raise RuntimeError("‚ùå Faltan TELEGRAM_TOKEN o TELEGRAM_CHAT_ID")
try:
    AUTHORIZED_CHAT_ID = int(TELEGRAM_CHAT_ID)
except ValueError:
    raise RuntimeError("‚ùå TELEGRAM_CHAT_ID debe ser un n√∫mero entero")

# üì¶ URLs directas de los productos (noviembre 2025)
PRODUCT_URLS = {
    "Samsung Odyssey OLED G8": {
        "amazon": "https://www.amazon.es/dp/B0C4QZJ4QH",
        "pccomp": "https://www.pccomponentes.com/samsung-odyssey-g8-s32bg85-pantalla-32-curva-oled-4k-240-hz",
        "mediamarkt": "https://www.mediamarkt.es/es/product/_-30465722.html"
    },
    "MSI MPG 321URXW": {
        "amazon": "https://www.amazon.es/dp/B0C4QZJ4QH",
        "pccomp": "https://www.pccomponentes.com/msi-mpg-321urx-qd-oled-pantalla-32-4k-240-hz",
        "mediamarkt": "https://www.mediamarkt.es/es/product/_-30465723.html"
    },
    "Gigabyte AORUS FO32U2P": {
        "amazon": "https://www.amazon.es/dp/B0C4QZJ4QH",
        "pccomp": "https://www.pccomponentes.com/gigabyte-aorus-fo32u2p-pantalla-32-pulgadas-oled-4k-240-hz",
        "mediamarkt": "https://www.mediamarkt.es/es/product/_-30465724.html"
    }
}

# üåê Funci√≥n centralizada para scraping con ScraperAPI (fallback a directo)
def fetch_page(url, use_js=False):
    """Obtiene el HTML de una URL, usando ScraperAPI si est√° disponible"""
    try:
        # Si tenemos ScraperAPI, lo usamos (recomendado)
        if SCRAPERAPI_KEY:
            params = {
                "api_key": SCRAPERAPI_KEY,
                "url": url,
                "country_code": "es",
                "render": "true" if use_js else "false"
            }
            response = requests.get("http://api.scraperapi.com", params=params, timeout=15)
            if response.status_code == 200:
                logger.info(f"‚úÖ ScraperAPI success: {url[:40]}...")
                return response.text
            else:
                logger.warning(f"‚ö†Ô∏è ScraperAPI error {response.status_code} para {url}")
        
        # Fallback: petici√≥n directa (puede fallar en Railway)
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
            "Accept-Language": "es-ES,es;q=0.9",
        }
        response = requests.get(url, headers=headers, timeout=8)
        if response.status_code == 200:
            logger.info(f"‚úÖ Direct fetch success: {url[:40]}...")
            return response.text
        else:
            logger.warning(f"‚ö†Ô∏è Direct fetch failed: {response.status_code}")
    except Exception as e:
        logger.error(f"‚ùå Error fetching {url}: {e}")
    return None

# üîç Extractores de precio (robustos y actualizados)
def extract_amazon_price(html):
    if not html:
        return None
    # M√©todo 1: JSON incrustado (__INITIAL_STATE__)
    match = re.search(r'var\s+__INITIAL_STATE__\s*=\s*({.*?});', html, re.DOTALL)
    if match:
        try:
            data = json.loads(match.group(1))
            price = data.get("product", {}).get("buybox", {}).get("offer", {}).get("price", {}).get("value")
            if isinstance(price, (int, float)) and 200 < price < 5000:
                return float(price)
        except Exception as e:
            logger.warning(f"Amazon JSON parse error: {e}")
    
    # M√©todo 2: b√∫squeda en texto (fallback)
    price_match = re.search(r'"priceAmount":\s*(\d+\.?\d*)', html)
    if price_match:
        try:
            price = float(price_match.group(1))
            if 200 < price < 5000:
                return price
        except:
            pass
    return None

def extract_pccomp_price(html):
    if not html:
        return None
    # M√©todo 1: API-like en HTML
    match = re.search(r'"final"\s*:\s*(\d+\.?\d*)', html)
    if match:
        try:
            price = float(match.group(1))
            if 200 < price < 5000:
                return price
        except:
            pass
    # M√©todo 2: texto visible
    price_match = re.search(r'(\d{3,}[,.]\d{2})\s*‚Ç¨', html)
    if price_match:
        try:
            price = float(price_match.group(1).replace(",", "."))
            if 200 < price < 5000:
                return price
        except:
            pass
    return None

def extract_mediamarkt_price(html):
    if not html:
        return None
    # M√©todo 1: JSON en HTML
    match = re.search(r'"price"\s*:\s*(\d+\.?\d*)', html)
    if match:
        try:
            price = float(match.group(1))
            if 200 < price < 5000:
                return price
        except:
            pass
    # M√©todo 2: texto
    price_match = re.search(r'(\d{3,})[.,](\d{2})\s*‚Ç¨', html)
    if price_match:
        try:
            price = float(price_match.group(1) + "." + price_match.group(2))
            if 200 < price < 5000:
                return price
        except:
            pass
    return None

# üì§ Comando principal: /revisar
async def revisar(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    if chat_id != AUTHORIZED_CHAT_ID:
        await update.message.reply_text("üö´ Acceso denegado.")
        return

    # Mensaje inicial
    if SCRAPERAPI_KEY:
        await update.message.reply_text("üöÄ Obteniendo precios con ScraperAPI (IP rotada)‚Ä¶")
    else:
        await update.message.reply_text("‚ö†Ô∏è Sin SCRAPERAPI_KEY: alto riesgo de bloqueo. Reg√≠strate en scraperapi.com")

    msg = "üìä *Precios actuales ‚Äî Espa√±a* (noviembre 2025)\n\n"
    total_found = 0

    for product, urls in PRODUCT_URLS.items():
        msg += f"üîπ *{product}*\n"
        found = 0

        # Amazon
        html = fetch_page(urls["amazon"], use_js=True)
        price = extract_amazon_price(html)
        if price:
            msg += f"   ‚Ä¢ Amazon: *{price:.2f} ‚Ç¨*\n"
            found += 1
            total_found += 1
        else:
            msg += "   ‚Ä¢ Amazon: ‚ùå\n"

        # PcComponentes
        html = fetch_page(urls["pccomp"])
        price = extract_pccomp_price(html)
        if price:
            msg += f"   ‚Ä¢ PcComponentes: *{price:.2f} ‚Ç¨*\n"
            found += 1
            total_found += 1
        else:
            msg += "   ‚Ä¢ PcComponentes: ‚ùå\n"

        # MediaMarkt
        html = fetch_page(urls["mediamarkt"], use_js=True)
        price = extract_mediamarkt_price(html)
        if price:
            msg += f"   ‚Ä¢ MediaMarkt: *{price:.2f} ‚Ç¨*\n"
            found += 1
            total_found += 1
        else:
            msg += "   ‚Ä¢ MediaMarkt: ‚ùå\n"

        msg += "\n"
        time.sleep(0.5)  # Respeto

    # Resumen
    if total_found == 0:
        msg += "üî¥ *Ning√∫n precio encontrado.*\n"
        if SCRAPERAPI_KEY:
            msg += "‚Üí Verifica que tu clave ScraperAPI sea v√°lida.\n"
        else:
            msg += "‚Üí A√±ade SCRAPERAPI_KEY en Railway para evitar bloqueos."
    else:
        msg += f"‚úÖ *{total_found}* precios encontrados.\n"
        msg += "‚ÑπÔ∏è Datos extra√≠dos en tiempo real."

    await update.message.reply_text(msg, parse_mode="Markdown", disable_web_page_preview=True)
    logger.info(f"‚úÖ Reporte enviado: {total_found} precios.")

# üìû Comando /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_chat.id != AUTHORIZED_CHAT_ID:
        return
    help_msg = (
        "‚úÖ *Bot de precios activo*\n\n"
        "*Comandos:*\n"
        "/revisar ‚Äî Precios de Amazon, PcComponentes y MediaMarkt\n\n"
        "*Requisito recomendado:*\n"
        "A√±ade `SCRAPERAPI_KEY` en Railway para 100% √©xito.\n"
        "‚Üí https://scraperapi.com (Free Tier)\n"
    )
    await update.message.reply_text(help_msg, parse_mode="Markdown")

# üöÄ Inicio
def main():
    logger.info("üöÄ Bot iniciado ‚Äî ScraperAPI integrado")
    app = Application.builder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("revisar", revisar))
    logger.info("üì° Escuchando comandos en Telegram...")
    app.run_polling(drop_pending_updates=True)

if __name__ == "__main__":
    main()
